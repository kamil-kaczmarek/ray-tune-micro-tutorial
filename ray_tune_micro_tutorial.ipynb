{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "# Micro tutorial on how to run and scale hyperparameter optimization with LightGBM and Tune\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/tune_overview.png\" alt=\"Tune and integrations\" width=\"500\">\n",
    "\n",
    "Aug 2022. San Francisco, CA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine(return_X_y=True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7707, stratify=y\n",
    ")\n",
    "\n",
    "train_data = lgb.Dataset(data=X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(data=X_valid, label=y_valid, reference=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) (classification) and create LightGBM Dataset object that will be used for training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: single LightGBM training session\n",
    "<img src=\"https://lightgbm.readthedocs.io/en/latest/_images/LightGBM_logo_black_text.svg\" alt=\"LightGBM Logo\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training parameters for single training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_parameters = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_class\": 3,\n",
    "    \"num_leaves\": 7,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"max_depth\": 5,\n",
    "    \"verbose\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LightGBM model and log results to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(\n",
    "    params=training_parameters,\n",
    "    train_set=train_data,\n",
    "    num_boost_round=10,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    callbacks=[lgb.log_evaluation(period=10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report accuracy on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(gbm.predict(X_valid), axis=1)\n",
    "acc = accuracy_score(y_true=y_valid, y_pred=y_pred)\n",
    "print(f\"Accuracy on valid set: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* We just ran single LightGBM training session. To do that we prepared dataset and training hyperparameters.\n",
    "* Next, let's have a closer look at Tune."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2: Tune quickstart\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/tune.png\" alt=\"Tune logo\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Tune\n",
    "There are few components that we should look at first:\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/tune_flow.png\" alt=\"Tune key concepts\" width=\"800\">\n",
    "\n",
    "Learn more about it from the [Key concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) docs page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Ray cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cluster will be used for all tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "cluster_info = ray.init()\n",
    "cluster_info.address_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_class\": 3,\n",
    "    \"num_leaves\": tune.choice([2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 100]),\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"feature_fraction\": tune.uniform(0.85, 0.999),\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": tune.randint(1, 11),\n",
    "    \"max_depth\": tune.randint(1, 11),\n",
    "    \"verbose\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(training_params, checkpoint_dir=None):\n",
    "    train_data = lgb.Dataset(data=X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(data=X_valid, label=y_valid, reference=train_data)\n",
    "\n",
    "    # Train LightGBM model and log results to stdout\n",
    "    gbm = lgb.train(\n",
    "        params=training_params,\n",
    "        train_set=train_data,\n",
    "        num_boost_round=10,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[lgb.log_evaluation(period=10)],\n",
    "    )\n",
    "\n",
    "    y_pred = np.argmax(gbm.predict(X_valid), axis=1)\n",
    "    acc = accuracy_score(y_true=y_valid, y_pred=y_pred)\n",
    "\n",
    "    # Send accuracy back to Tune\n",
    "    tune.report(valid_acc=acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter tuning, single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(train_lgbm, config=search_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy from the best trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe(metric=\"valid_acc\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* We just ran first trial using Tune.\n",
    "* Next, we will modify `tune.run()` in order to run tuning with 300 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Execute 300 tuning runs with Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    train_lgbm,\n",
    "    config=search_space,\n",
    "    num_samples=300,\n",
    "    metric=\"valid_acc\",\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy from the best trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe(metric=\"valid_acc\")\n",
    "df.sort_values(by=[\"valid_acc\"], ascending=False).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Population Based Training with Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Population Based Training\n",
    "<img src=\"https://assets-global.website-files.com/621e749a546b7592125f38ed/62267281d1276db85e98c705_PBT%203.jpg\" alt=\"Tune key concepts\" width=\"500\">\n",
    "\n",
    "Learn more about Population based training of neural networks from the [blogpost](https://www.deepmind.com/blog/population-based-training-of-neural-networks) or [paper](https://arxiv.org/abs/1711.09846)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Population Based Training from Tune schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import PopulationBasedTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Population Based Training scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbt_scheduler = PopulationBasedTraining(\n",
    "    time_attr=\"time_total_s\",\n",
    "    mode=\"max\",\n",
    "    perturbation_interval=3,\n",
    "    hyperparam_mutations={\n",
    "        \"num_leaves\": tune.choice([2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40, 100]),\n",
    "        \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"feature_fraction\": tune.uniform(0.85, 0.999),\n",
    "        \"bagging_freq\": tune.randint(1, 11),\n",
    "        \"max_depth\": tune.randint(1, 11),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter tuning with Population Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    train_lgbm,\n",
    "    config=search_space,\n",
    "    num_samples=300,\n",
    "    metric=\"valid_acc\",\n",
    "    resources_per_trial={\"cpu\": 1},\n",
    "    scheduler=pbt_scheduler,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display accuracy from the best trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analysis.dataframe(metric=\"valid_acc\")\n",
    "df.sort_values(by=[\"valid_acc\"], ascending=False).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* We ran hyperparameter tuning with 300 trials using Population based Training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown Ray cluster\n",
    "Shutdown ray cluster at the end of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats!\n",
    "\n",
    "You just finished the micro tutorial on how to run and scale hyperparameter optimization with LightGBM and Tune.\n",
    "\n",
    "Now, please go to the [micro tutorial README](https://github.com/kamil-kaczmarek/ray-tune-micro-tutorial/blob/kk/dev/README.md), to learn more about next steps, and options to reach out and connect with the community."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
